{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ä½¿ç”¨ Unsloth å¯¹ DeepSeek-R1-Distill-Qwen-1.5B æ¨¡å‹è¿›è¡Œ LoRA å¾®è°ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T13:30:54.074191Z",
     "iopub.status.busy": "2025-08-31T13:30:54.073486Z",
     "iopub.status.idle": "2025-08-31T13:30:54.077237Z",
     "shell.execute_reply": "2025-08-31T13:30:54.076732Z",
     "shell.execute_reply.started": "2025-08-31T13:30:54.074153Z"
    }
   },
   "source": [
    "### 1. ç¯å¢ƒå‡†å¤‡ä¸åº“å¯¼å…¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T13:31:04.386381Z",
     "iopub.status.busy": "2025-08-31T13:31:04.385841Z",
     "iopub.status.idle": "2025-08-31T13:31:04.389180Z",
     "shell.execute_reply": "2025-08-31T13:31:04.388679Z",
     "shell.execute_reply.started": "2025-08-31T13:31:04.386356Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-31T13:29:46.360862Z",
     "start_time": "2025-08-31T13:29:36.063611Z"
    },
    "execution": {
     "iopub.execute_input": "2025-08-31T13:31:05.340718Z",
     "iopub.status.busy": "2025-08-31T13:31:05.340346Z",
     "iopub.status.idle": "2025-08-31T13:31:16.004869Z",
     "shell.execute_reply": "2025-08-31T13:31:16.004237Z",
     "shell.execute_reply.started": "2025-08-31T13:31:05.340696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/deepseek-quickstart/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from unsloth import FastLanguageModel\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, GenerationConfig, DataCollatorForSeq2Seq\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å’Œåˆ†è¯å™¨ (Tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰æ¨¡å‹å’Œä¸€äº›åŸºæœ¬å‚æ•°\n",
    "max_seq_length = 8192\n",
    "dtype = None # None è¡¨ç¤ºè‡ªåŠ¨é€‰æ‹© (Float16 a T4, V100, BFloat16 a Ampere)\n",
    "load_in_4bit = True # ä½¿ç”¨ 4bit é‡åŒ–åŠ è½½\n",
    "\n",
    "# è¿™æ˜¯æ‚¨çš„æ¨¡å‹æ ‡è¯†ç¬¦ï¼Œè¯·æ›¿æ¢ä¸ºæ‚¨æ­£åœ¨ä½¿ç”¨çš„æ¨¡å‹\n",
    "# ä¾‹å¦‚ï¼š\"qwen-1.5b_lora_model\"\n",
    "# model_name = \"qwen-1.5b_lora_model\" \n",
    "# model_name = \"unsloth/DeepSeek-R1-Distill-Qwen-1.5B\" \n",
    "model_name = \"unsloth/DeepSeek-R1-Distill-Qwen-1.5B-unsloth-bnb-4bit\" \n",
    "\n",
    "# è¿™ä¸€æ­¥ä¼šè¿”å›ä¸€ä¸ªç»è¿‡ Unsloth ä¼˜åŒ–çš„æ¨¡å‹å’Œä¸€ä¸ªåˆ†è¯å™¨\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_name,\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. å¾®è°ƒå‰æ¨ç†æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T13:31:32.287700Z",
     "iopub.status.busy": "2025-08-31T13:31:32.286811Z",
     "iopub.status.idle": "2025-08-31T13:31:32.291711Z",
     "shell.execute_reply": "2025-08-31T13:31:32.290894Z",
     "shell.execute_reply.started": "2025-08-31T13:31:32.287674Z"
    }
   },
   "outputs": [],
   "source": [
    "# æ¨¡å‹æ¨ç†çš„ Prompt æ¨¡æ¿\n",
    "inference_prompt = \"\"\"ä»¥ä¸‹æ˜¯ä¸€æ¡æè¿°ä»»åŠ¡çš„æŒ‡ä»¤ï¼Œå¹¶é…æœ‰ä¸€ä¸ªæä¾›è¿›ä¸€æ­¥ä¸Šä¸‹æ–‡çš„è¾“å…¥ã€‚\n",
    "è¯·æ’°å†™ä¸€ä»½æ°å½“çš„å›å¤ï¼Œä»¥å®Œæˆè¯¥è¯·æ±‚ã€‚\n",
    "åœ¨å›ç­”ä¹‹å‰ï¼Œè¯·ä»”ç»†æ€è€ƒè¯¥é—®é¢˜ï¼Œå¹¶æ„å»ºä¸€ä¸ªåˆ†æ­¥çš„æ€è€ƒè¿‡ç¨‹ï¼Œä»¥ç¡®ä¿å›åº”çš„é€»è¾‘ä¸¥è°¨å’Œå†…å®¹å‡†ç¡®ã€‚\n",
    "\n",
    "\n",
    "### Instruction:\n",
    "ä½ æ˜¯ä¸€ä½åŒ»å­¦ä¸“å®¶ï¼Œåœ¨ä¸´åºŠæ¨ç†ã€è¯Šæ–­å­¦å’Œæ²»ç–—è§„åˆ’æ–¹é¢æ‹¥æœ‰æ·±åšçš„ä¸“ä¸šçŸ¥è¯†ã€‚\n",
    "è¯·å›ç­”ä»¥ä¸‹åŒ»å­¦é—®é¢˜ã€‚\n",
    "\n",
    "### Question:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "<think>{}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T13:31:36.723913Z",
     "iopub.status.busy": "2025-08-31T13:31:36.723363Z",
     "iopub.status.idle": "2025-08-31T13:31:51.983657Z",
     "shell.execute_reply": "2025-08-31T13:31:51.983028Z",
     "shell.execute_reply.started": "2025-08-31T13:31:36.723887Z"
    }
   },
   "outputs": [],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "question = \"ç”·ï¼Œ28å²ï¼Œç¨‹åºå‘˜ï¼Œæœ€è¿‘ä¸€å‘¨æ¯å¤©å·¥ä½œåˆ°åŠå¤œï¼Œæ„Ÿè§‰å¤´æ™•ã€è„–å­ç–¼ï¼Œæœ‰æ—¶å€™è¿˜æ¶å¿ƒã€‚\"\n",
    "\n",
    "inputs = tokenizer([inference_prompt.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
    "attention_mask = inputs.input_ids.ne(tokenizer.pad_token_id).long().to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids=inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    max_new_tokens=1200,\n",
    "    use_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T13:32:10.239626Z",
     "iopub.status.busy": "2025-08-31T13:32:10.239104Z",
     "iopub.status.idle": "2025-08-31T13:32:10.243234Z",
     "shell.execute_reply": "2025-08-31T13:32:10.242708Z",
     "shell.execute_reply.started": "2025-08-31T13:32:10.239602Z"
    }
   },
   "outputs": [],
   "source": [
    "response = tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T13:32:11.373734Z",
     "iopub.status.busy": "2025-08-31T13:32:11.373422Z",
     "iopub.status.idle": "2025-08-31T13:32:11.377432Z",
     "shell.execute_reply": "2025-08-31T13:32:11.376880Z",
     "shell.execute_reply.started": "2025-08-31T13:32:11.373712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<think>\n",
      "å¥½çš„ï¼Œæˆ‘éœ€è¦åˆ†æè¿™ä½28å²çš„ç”·æ€§ï¼Œä»–æ˜¯ä¸€åç¨‹åºå‘˜ï¼Œæœ€è¿‘ä¸€å‘¨æ¯å¤©å·¥ä½œåˆ°åŠå¤œï¼Œå‡ºç°å¤´æ™•ã€è„–å­ç–¼å’Œæ¶å¿ƒç­‰ç—‡çŠ¶ã€‚é¦–å…ˆï¼Œå¤´æ™•å’Œè„–å­ç–¼å¯èƒ½æ˜¯è„‘åŠ›è¿åŠ¨å¯¼è‡´çš„ï¼Œä½†æŒç»­çš„æ—¶é—´å’Œé¢‘ç‡å¯èƒ½æç¤ºæœ‰ç¥ç»ç³»ç»Ÿç–¾ç—…ï¼Œå¦‚è„‘è†œç‚ã€ä¸­é£æˆ–è„‘è†œç‚ã€‚æ¶å¿ƒå¯èƒ½æ˜¯èƒƒé…¸è¿‡å¤šå¼•èµ·çš„èƒƒé£Ÿç®¡åæµç—‡çŠ¶ã€‚è€ƒè™‘åˆ°ä»–å·¥ä½œæ—¶é—´é•¿æœŸï¼Œå¯èƒ½éœ€è¦ä¼‘æ¯æˆ–è°ƒæ•´å·¥ä½œæ–¹å¼ã€‚\n",
      "\n",
      "æ¥ä¸‹æ¥ï¼Œæˆ‘éœ€è¦è€ƒè™‘æ˜¯å¦æœ‰å…¶ä»–å¯èƒ½çš„è§£é‡Šï¼Œæ¯”å¦‚ä¸­é£æˆ–è„‘è†œç‚ã€‚ä¸­é£å¯èƒ½éœ€è¦ç«‹å³å°±åŒ»ï¼Œä½†å¦‚æœæ˜¯é•¿æœŸåŠ ç­å¯¼è‡´çš„æŒç»­æ€§ç–¼ç—›ï¼Œå¯èƒ½éœ€è¦è§‚å¯Ÿå’Œä¼‘æ¯ã€‚æ¶å¿ƒå¯èƒ½ä¸èƒƒé…¸è¿‡å¤šæœ‰å…³ï¼Œå¯èƒ½éœ€è¦èƒƒè¯æ²»ç–—ï¼Œä½†éœ€è¦åœ¨åŒ»ç”ŸæŒ‡å¯¼ä¸‹è¿›è¡Œã€‚\n",
      "\n",
      "æ­¤å¤–ï¼Œæˆ‘éœ€è¦è€ƒè™‘æ˜¯å¦æœ‰å…¶ä»–å› ç´ ï¼Œæ¯”å¦‚ç¡çœ è´¨é‡ã€‚é•¿æ—¶é—´å·¥ä½œå¯èƒ½å¯¼è‡´ç¡çœ ä¸è¶³ï¼Œå½±å“ç¥ç»åŠŸèƒ½ã€‚å¦‚æœä»–æœ€è¿‘æœ‰ç¡çœ é—®é¢˜ï¼Œå¯èƒ½éœ€è¦æ”¹å–„ç¡çœ ä¹ æƒ¯ï¼Œæ¯”å¦‚æ—©ç¡æ—©èµ·ï¼Œé¿å…è¿‡åº¦åŠ³ç´¯ã€‚\n",
      "\n",
      "ç»¼åˆæ¥çœ‹ï¼Œå»ºè®®ä»–ç«‹å³å°±åŒ»ï¼Œä»¥æ’é™¤å¯èƒ½çš„ä¸­é£æˆ–è„‘è†œç‚ã€‚åŒæ—¶ï¼Œè§‚å¯Ÿæ˜¯å¦æœ‰å…¶ä»–ç—‡çŠ¶ï¼Œå¦‚æ¶å¿ƒå¯èƒ½éœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥ã€‚å»ºè®®ä»–å¯»æ±‚ä¸“ä¸šåŒ»ç”Ÿçš„è¯Šæ–­å’Œæ²»ç–—ï¼Œä»¥ç¡®ä¿ä»–çš„å¥åº·çŠ¶å†µå¾—åˆ°å¦¥å–„å¤„ç†ã€‚\n",
      "</think>\n",
      "\n",
      "é¦–å…ˆï¼Œæ ¹æ®æ‚£è€…çš„æè¿°ï¼Œå¤´æ™•ã€è„–å­ç–¼å’Œæ¶å¿ƒå¯èƒ½æ˜¯ç”±ä¸­é£ã€è„‘è†œç‚æˆ–å…¶ä»–ç¥ç»ç³»ç»Ÿç–¾ç—…å¼•èµ·çš„ã€‚è€ƒè™‘åˆ°ä»–çš„å·¥ä½œé•¿æœŸæ€§å’ŒæŒç»­æ€§ç–¼ç—›ï¼Œå»ºè®®ç«‹å³å°±åŒ»ï¼Œä»¥æ’é™¤å¯èƒ½çš„ä¸­é£æˆ–è„‘è†œç‚ã€‚å¦‚æœå‡ºç°èƒƒé…¸è¿‡å¤šå¯¼è‡´çš„æ¶å¿ƒï¼Œå¯èƒ½éœ€è¦èƒƒè¯æ²»ç–—ï¼Œä½†éœ€åœ¨åŒ»ç”ŸæŒ‡å¯¼ä¸‹è¿›è¡Œã€‚å»ºè®®ä»–å°½å¿«ä¸åŒ»ç”Ÿæ²Ÿé€šï¼Œè§‚å¯Ÿæ˜¯å¦æœ‰å…¶ä»–ç—‡çŠ¶ï¼Œå¦‚æ¶å¿ƒï¼Œä»¥åŠæ˜¯å¦æœ‰å…¶ä»–å¥åº·é—®é¢˜ã€‚å»ºè®®ä»–å¯»æ±‚ä¸“ä¸šåŒ»ç”Ÿçš„è¯Šæ–­å’Œæ²»ç–—ï¼Œä»¥ç¡®ä¿ä»–çš„å¥åº·çŠ¶å†µå¾—åˆ°å¦¥å–„å¤„ç†ã€‚\n"
     ]
    }
   ],
   "source": [
    "print(response[0].split(\"### Response:\")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. ä¸‹è½½å’Œæ ¼å¼åŒ–è®­ç»ƒæ•°æ®é›†\n",
    "\n",
    "åŒ»å­¦æ¨ç†æ•°æ®é›†ï¼šhttps://huggingface.co/datasets/FreedomIntelligence/medical-o1-reasoning-SFT/viewer/zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T13:32:26.892278Z",
     "iopub.status.busy": "2025-08-31T13:32:26.891701Z",
     "iopub.status.idle": "2025-08-31T13:32:26.895464Z",
     "shell.execute_reply": "2025-08-31T13:32:26.894805Z",
     "shell.execute_reply.started": "2025-08-31T13:32:26.892254Z"
    }
   },
   "outputs": [],
   "source": [
    "# æ¨¡å‹è®­ç»ƒçš„ Prompt æ¨¡æ¿\n",
    "train_prompt = \"\"\"ä»¥ä¸‹æ˜¯ä¸€æ¡æè¿°ä»»åŠ¡çš„æŒ‡ä»¤ï¼Œå¹¶é…æœ‰ä¸€ä¸ªæä¾›è¿›ä¸€æ­¥ä¸Šä¸‹æ–‡çš„è¾“å…¥ã€‚\n",
    "è¯·æ’°å†™ä¸€ä»½æ°å½“çš„å›å¤ï¼Œä»¥å®Œæˆè¯¥è¯·æ±‚ã€‚\n",
    "åœ¨å›ç­”ä¹‹å‰ï¼Œè¯·ä»”ç»†æ€è€ƒè¯¥é—®é¢˜ï¼Œå¹¶æ„å»ºä¸€ä¸ªåˆ†æ­¥çš„æ€è€ƒè¿‡ç¨‹ï¼Œä»¥ç¡®ä¿å›åº”çš„é€»è¾‘ä¸¥è°¨å’Œå†…å®¹å‡†ç¡®ã€‚\n",
    "\n",
    "\n",
    "### Instruction:\n",
    "ä½ æ˜¯ä¸€ä½åŒ»å­¦ä¸“å®¶ï¼Œåœ¨ä¸´åºŠæ¨ç†ã€è¯Šæ–­å­¦å’Œæ²»ç–—è§„åˆ’æ–¹é¢æ‹¥æœ‰æ·±åšçš„ä¸“ä¸šçŸ¥è¯†ã€‚\n",
    "è¯·å›ç­”ä»¥ä¸‹åŒ»å­¦é—®é¢˜ã€‚\n",
    "\n",
    "### Question:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "<think>\n",
    "{}\n",
    "</think>\n",
    "{}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T13:32:30.692649Z",
     "iopub.status.busy": "2025-08-31T13:32:30.692105Z",
     "iopub.status.idle": "2025-08-31T13:32:34.379164Z",
     "shell.execute_reply": "2025-08-31T13:32:34.378563Z",
     "shell.execute_reply.started": "2025-08-31T13:32:30.692625Z"
    }
   },
   "outputs": [],
   "source": [
    "EOS_TOKEN = tokenizer.eos_token # æ·»åŠ  EOS Token\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    inputs = examples[\"Question\"]\n",
    "    cots = examples[\"Complex_CoT\"]\n",
    "    outputs = examples[\"Response\"]\n",
    "    texts = []\n",
    "    for input, cot, output in zip(inputs, cots, outputs):\n",
    "        # å°† EOS Token æ·»åŠ åˆ°æ ·æœ¬æœ€å\n",
    "        text = train_prompt.format(input, cot, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "pass\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"FreedomIntelligence/medical-o1-reasoning-SFT\", \"zh\", split = \"train\")\n",
    "dataset = dataset.map(formatting_prompts_func, batched = True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T13:32:40.855406Z",
     "iopub.status.busy": "2025-08-31T13:32:40.854954Z",
     "iopub.status.idle": "2025-08-31T13:32:40.863683Z",
     "shell.execute_reply": "2025-08-31T13:32:40.863070Z",
     "shell.execute_reply.started": "2025-08-31T13:32:40.855375Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ä»¥ä¸‹æ˜¯ä¸€æ¡æè¿°ä»»åŠ¡çš„æŒ‡ä»¤ï¼Œå¹¶é…æœ‰ä¸€ä¸ªæä¾›è¿›ä¸€æ­¥ä¸Šä¸‹æ–‡çš„è¾“å…¥ã€‚\\nè¯·æ’°å†™ä¸€ä»½æ°å½“çš„å›å¤ï¼Œä»¥å®Œæˆè¯¥è¯·æ±‚ã€‚\\nåœ¨å›ç­”ä¹‹å‰ï¼Œè¯·ä»”ç»†æ€è€ƒè¯¥é—®é¢˜ï¼Œå¹¶æ„å»ºä¸€ä¸ªåˆ†æ­¥çš„æ€è€ƒè¿‡ç¨‹ï¼Œä»¥ç¡®ä¿å›åº”çš„é€»è¾‘ä¸¥è°¨å’Œå†…å®¹å‡†ç¡®ã€‚\\n\\n\\n### Instruction:\\nä½ æ˜¯ä¸€ä½åŒ»å­¦ä¸“å®¶ï¼Œåœ¨ä¸´åºŠæ¨ç†ã€è¯Šæ–­å­¦å’Œæ²»ç–—è§„åˆ’æ–¹é¢æ‹¥æœ‰æ·±åšçš„ä¸“ä¸šçŸ¥è¯†ã€‚\\nè¯·å›ç­”ä»¥ä¸‹åŒ»å­¦é—®é¢˜ã€‚\\n\\n### Question:\\næ ¹æ®æè¿°ï¼Œä¸€ä¸ª1å²çš„å­©å­åœ¨å¤å­£å¤´çš®å‡ºç°å¤šå¤„å°ç»“èŠ‚ï¼Œé•¿æœŸä¸æ„ˆåˆï¼Œä¸”ç°åœ¨ç–®å¤§å¦‚æ¢…ï¼Œæºƒç ´æµè„“ï¼Œå£ä¸æ”¶æ•›ï¼Œå¤´çš®ä¸‹æœ‰ç©ºæ´ï¼Œæ‚£å¤„çš®è‚¤å¢åšã€‚è¿™ç§ç—…ç—‡åœ¨ä¸­åŒ»ä¸­è¯Šæ–­ä¸ºä»€ä¹ˆç—…ï¼Ÿ\\n\\n### Response:\\n<think>\\nè¿™ä¸ªå°å­©å­åœ¨å¤å¤©å¤´çš®ä¸Šé•¿äº†äº›å°ç»“èŠ‚ï¼Œä¸€ç›´éƒ½æ²¡å¥½ï¼Œåæ¥å˜æˆäº†è„“åŒ…ï¼Œæµäº†å¥½å¤šè„“ã€‚æƒ³æƒ³å¤å¤©é‚£ä¹ˆçƒ­ï¼Œå¯èƒ½å’Œæ¹¿çƒ­æœ‰å…³ã€‚æ‰ä¸€å²çš„å°å­©ï¼Œå…ç–«åŠ›æœ¬æ¥å°±ä¸å¼ºï¼Œå¤å¤©çš„æ¹¿çƒ­æ²¡å‡†å°±ä¾µè¢­äº†èº«ä½“ã€‚\\n\\nç”¨ä¸­åŒ»çš„è§’åº¦æ¥çœ‹ï¼Œå‡ºç°å°ç»“èŠ‚ã€å†åŠ ä¸Šé•¿æœŸä¸æ„ˆåˆï¼Œè¿™äº›ç—‡çŠ¶è®©æˆ‘æƒ³åˆ°äº†å¤´ç–®ã€‚å°å­©å­æœ€å®¹æ˜“å¾—è¿™äº›çš®è‚¤ç—…ï¼Œä¸»è¦å› ä¸ºæ¹¿çƒ­åœ¨ä½“è¡¨éƒç»“ã€‚\\n\\nä½†å†çœ‹çœ‹ï¼Œå¤´çš®ä¸‹è¿˜æœ‰ç©ºæ´ï¼Œè¿™å¯èƒ½ä¸æ­¢æ˜¯ç®€å•çš„å¤´ç–®ã€‚çœ‹èµ·æ¥ç—…æƒ…æŒºä¸¥é‡çš„ï¼Œä¹Ÿè®¸æ˜¯è„“è‚¿æ²¡æ²»å¥½ã€‚è¿™æ ·çš„æƒ…å†µä¸­åŒ»ä¸­æœ‰æ—¶å€™å«åšç¦¿ç–®æˆ–è€…æ¹¿ç–®ï¼Œä¹Ÿå¯èƒ½æ˜¯å¦ä¸€ç§æƒ…å†µã€‚\\n\\nç­‰ä¸€ä¸‹ï¼Œå¤´çš®ä¸Šçš„ç©ºæ´å’Œçš®è‚¤å¢åšæ›´åƒæ˜¯ç–¾ç—…å·²ç»æ·±å…¥åˆ°å¤´çš®ä¸‹ï¼Œè¿™æ˜¯ä¸æ˜¯è¯´æ˜æœ‰å¯èƒ½æ˜¯æµæ³¨æˆ–ç˜°ç–¬ï¼Ÿè¿™äº›åå­—å¸¸æè¿°å¤´éƒ¨æˆ–é¢ˆéƒ¨çš„ä¸¥é‡æ„ŸæŸ“ï¼Œç‰¹åˆ«æ˜¯æœ‰åŒ–è„“ä¸æ„ˆåˆï¼Œåˆå½¢æˆé€šé“æˆ–ç©ºæ´çš„æƒ…å†µã€‚\\n\\nä»”ç»†æƒ³æƒ³ï¼Œæˆ‘æ€ä¹ˆæ„Ÿè§‰è¿™äº›ç—‡çŠ¶æ›´è´´è¿‘ç˜°ç–¬çš„è¡¨ç°ï¼Ÿå°¤å…¶è€ƒè™‘åˆ°å­©å­çš„å¹´çºªå’Œå¤å¤©å‘ç”Ÿçš„å­£èŠ‚æ€§å› ç´ ï¼Œæ¹¿çƒ­å¯èƒ½æ˜¯ä¸»å› ï¼Œä½†å¯èƒ½ä¹Ÿæœ‰ç«æ¯’æˆ–è€…ç—°æ¹¿é€ æˆçš„æ»ç•™ã€‚\\n\\nå›åˆ°åŸºæœ¬çš„ç—‡çŠ¶æè¿°ä¸Šçœ‹ï¼Œè¿™ç§é•¿æœŸä¸æ„ˆåˆåˆå¤æ‚çš„çŠ¶å†µï¼Œå¦‚æœç»“åˆä¸­åŒ»æ›´åé‡çš„ç—…åï¼Œæ˜¯ä¸æ˜¯æœ‰å¯èƒ½æ˜¯æ¶‰åŠæ›´æ·±å±‚æ¬¡çš„æ„ŸæŸ“ï¼Ÿ\\n\\nå†è€ƒè™‘ä¸€ä¸‹ï¼Œè¿™åº”è¯¥ä¸æ˜¯å•çº¯çš„ç˜°ç–¬ï¼Œå¾—ä»”ç»†åˆ†æå¤´çš®å¢åšå¹¶å‡ºç°ç©ºæ´è¿™æ ·çš„ä¸¥é‡ç—‡çŠ¶ã€‚ä¸­åŒ»é‡Œå¤´ï¼Œè¿™æ ·çš„è¡¨ç°å¯èƒ½æ›´ç¬¦åˆâ€˜èš€ç–®â€™æˆ–â€˜å¤´ç–½â€™ã€‚è¿™äº›ç—…åé€šå¸¸æè¿°å¤´éƒ¨ä¸¥é‡æ„ŸæŸ“åçš„æºƒçƒ‚å’Œç»„ç»‡åæ­»ã€‚\\n\\nçœ‹çœ‹å­£èŠ‚å’Œå­©å­çš„ä½“è´¨ï¼Œå¤å¤©åˆæ¹¿åˆçƒ­ï¼Œå¤–é‚ªå¾ˆå®¹æ˜“ä¾µå…¥å¤´éƒ¨ï¼Œå¯¹å­©å­è¿™ä¹ˆå¼±çš„å…ç–«ç³»ç»Ÿç®€ç›´å°±æ˜¯æŒ‘æˆ˜ã€‚å¤´ç–½è¿™ä¸ªç—…åå¬èµ·æ¥çœŸæ˜¯åˆ‡åˆï¼Œå› ä¸ºå®ƒæè¿°çš„æ„ŸæŸ“ä¸¥é‡ï¼Œæºƒçƒ‚åˆ°å‡ºç°ç©ºæ´ã€‚\\n\\nä¸è¿‡ï¼Œä»”ç»†ç¢ç£¨åå‘ç°ï¼Œè¿˜æœ‰ä¸ªç—…åä¼¼ä¹æ›´ä¸ºåˆé€‚ï¼Œå«åšâ€˜è¼è›„ç––â€™ï¼Œè¿™ç—…åœ¨ä¸­åŒ»é‡Œä¸“æŒ‡åƒè¿™ç§ä¸¥é‡æ„ŸæŸ“å¹¶ä¼´æœ‰æ·±éƒ¨ç©ºæ´çš„æƒ…å†µã€‚å®ƒä¹Ÿæ¶µç›–äº†åŒ–è„“å’Œçš®è‚¤å¢åšè¿™äº›ç—‡çŠ¶ã€‚\\n\\nå“¦ï¼Œè¯¥ä¸ä¼šæ˜¯å¤å­£æ¹¿çƒ­ï¼Œå¯¼è‡´æ¹¿æ¯’å…¥ä¾µï¼Œå­©å­çš„ä½“è´¨ä¸èƒ½å¾¡ï¼Œå…¶ç—…æƒ…å‘å±•æˆè¿™æ ·çš„æ„ŸæŸ“ï¼Ÿç»¼åˆåˆ†æåæˆ‘è§‰å¾—â€˜è¼è›„ç––â€™è¿™ä¸ªç—…åçœŸæ˜¯ç›¸å½“ç¬¦åˆã€‚\\n</think>\\nä»ä¸­åŒ»çš„è§’åº¦æ¥çœ‹ï¼Œä½ æ‰€æè¿°çš„ç—‡çŠ¶ç¬¦åˆâ€œè¼è›„ç––â€çš„ç—…ç—‡ã€‚è¿™ç§ç—…ç—‡é€šå¸¸å‘ç”Ÿåœ¨å¤´çš®ï¼Œè¡¨ç°ä¸ºå¤šå¤„ç»“èŠ‚ï¼Œæºƒç ´æµè„“ï¼Œå½¢æˆç©ºæ´ï¼Œæ‚£å¤„çš®è‚¤å¢åšä¸”é•¿æœŸä¸æ„ˆåˆã€‚æ¹¿çƒ­è¾ƒé‡çš„å¤å­£æ›´å®¹æ˜“å¯¼è‡´è¿™ç§ç—…ç—‡çš„å‘å±•ï¼Œç‰¹åˆ«æ˜¯åœ¨å…ç–«åŠ›è¾ƒå¼±çš„å„¿ç«¥èº«ä¸Šã€‚å»ºè®®ç»“åˆä¸­åŒ»çš„æ¸…çƒ­è§£æ¯’ã€ç¥›æ¹¿æ¶ˆè‚¿çš„æ²»ç–—æ–¹æ³•è¿›è¡Œå¤„ç†ï¼Œå¹¶é…åˆä¸“ä¸šçš„åŒ»ç–—å»ºè®®è¿›è¡Œè¯¦ç»†è¯Šæ–­å’Œæ²»ç–—ã€‚\\n<ï½œendâ–ofâ–sentenceï½œ>'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T13:32:44.745630Z",
     "iopub.status.busy": "2025-08-31T13:32:44.745057Z",
     "iopub.status.idle": "2025-08-31T13:32:44.750003Z",
     "shell.execute_reply": "2025-08-31T13:32:44.749468Z",
     "shell.execute_reply.started": "2025-08-31T13:32:44.745604Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "ä»¥ä¸‹æ˜¯ä¸€æ¡æè¿°ä»»åŠ¡çš„æŒ‡ä»¤ï¼Œå¹¶é…æœ‰ä¸€ä¸ªæä¾›è¿›ä¸€æ­¥ä¸Šä¸‹æ–‡çš„è¾“å…¥ã€‚\n",
       "è¯·æ’°å†™ä¸€ä»½æ°å½“çš„å›å¤ï¼Œä»¥å®Œæˆè¯¥è¯·æ±‚ã€‚\n",
       "åœ¨å›ç­”ä¹‹å‰ï¼Œè¯·ä»”ç»†æ€è€ƒè¯¥é—®é¢˜ï¼Œå¹¶æ„å»ºä¸€ä¸ªåˆ†æ­¥çš„æ€è€ƒè¿‡ç¨‹ï¼Œä»¥ç¡®ä¿å›åº”çš„é€»è¾‘ä¸¥è°¨å’Œå†…å®¹å‡†ç¡®ã€‚\n",
       "\n",
       "\n",
       "### Instruction:\n",
       "ä½ æ˜¯ä¸€ä½åŒ»å­¦ä¸“å®¶ï¼Œåœ¨ä¸´åºŠæ¨ç†ã€è¯Šæ–­å­¦å’Œæ²»ç–—è§„åˆ’æ–¹é¢æ‹¥æœ‰æ·±åšçš„ä¸“ä¸šçŸ¥è¯†ã€‚\n",
       "è¯·å›ç­”ä»¥ä¸‹åŒ»å­¦é—®é¢˜ã€‚\n",
       "\n",
       "### Question:\n",
       "æ ¹æ®æè¿°ï¼Œä¸€ä¸ª1å²çš„å­©å­åœ¨å¤å­£å¤´çš®å‡ºç°å¤šå¤„å°ç»“èŠ‚ï¼Œé•¿æœŸä¸æ„ˆåˆï¼Œä¸”ç°åœ¨ç–®å¤§å¦‚æ¢…ï¼Œæºƒç ´æµè„“ï¼Œå£ä¸æ”¶æ•›ï¼Œå¤´çš®ä¸‹æœ‰ç©ºæ´ï¼Œæ‚£å¤„çš®è‚¤å¢åšã€‚è¿™ç§ç—…ç—‡åœ¨ä¸­åŒ»ä¸­è¯Šæ–­ä¸ºä»€ä¹ˆç—…ï¼Ÿ\n",
       "\n",
       "### Response:\n",
       "<think>\n",
       "è¿™ä¸ªå°å­©å­åœ¨å¤å¤©å¤´çš®ä¸Šé•¿äº†äº›å°ç»“èŠ‚ï¼Œä¸€ç›´éƒ½æ²¡å¥½ï¼Œåæ¥å˜æˆäº†è„“åŒ…ï¼Œæµäº†å¥½å¤šè„“ã€‚æƒ³æƒ³å¤å¤©é‚£ä¹ˆçƒ­ï¼Œå¯èƒ½å’Œæ¹¿çƒ­æœ‰å…³ã€‚æ‰ä¸€å²çš„å°å­©ï¼Œå…ç–«åŠ›æœ¬æ¥å°±ä¸å¼ºï¼Œå¤å¤©çš„æ¹¿çƒ­æ²¡å‡†å°±ä¾µè¢­äº†èº«ä½“ã€‚\n",
       "\n",
       "ç”¨ä¸­åŒ»çš„è§’åº¦æ¥çœ‹ï¼Œå‡ºç°å°ç»“èŠ‚ã€å†åŠ ä¸Šé•¿æœŸä¸æ„ˆåˆï¼Œè¿™äº›ç—‡çŠ¶è®©æˆ‘æƒ³åˆ°äº†å¤´ç–®ã€‚å°å­©å­æœ€å®¹æ˜“å¾—è¿™äº›çš®è‚¤ç—…ï¼Œä¸»è¦å› ä¸ºæ¹¿çƒ­åœ¨ä½“è¡¨éƒç»“ã€‚\n",
       "\n",
       "ä½†å†çœ‹çœ‹ï¼Œå¤´çš®ä¸‹è¿˜æœ‰ç©ºæ´ï¼Œè¿™å¯èƒ½ä¸æ­¢æ˜¯ç®€å•çš„å¤´ç–®ã€‚çœ‹èµ·æ¥ç—…æƒ…æŒºä¸¥é‡çš„ï¼Œä¹Ÿè®¸æ˜¯è„“è‚¿æ²¡æ²»å¥½ã€‚è¿™æ ·çš„æƒ…å†µä¸­åŒ»ä¸­æœ‰æ—¶å€™å«åšç¦¿ç–®æˆ–è€…æ¹¿ç–®ï¼Œä¹Ÿå¯èƒ½æ˜¯å¦ä¸€ç§æƒ…å†µã€‚\n",
       "\n",
       "ç­‰ä¸€ä¸‹ï¼Œå¤´çš®ä¸Šçš„ç©ºæ´å’Œçš®è‚¤å¢åšæ›´åƒæ˜¯ç–¾ç—…å·²ç»æ·±å…¥åˆ°å¤´çš®ä¸‹ï¼Œè¿™æ˜¯ä¸æ˜¯è¯´æ˜æœ‰å¯èƒ½æ˜¯æµæ³¨æˆ–ç˜°ç–¬ï¼Ÿè¿™äº›åå­—å¸¸æè¿°å¤´éƒ¨æˆ–é¢ˆéƒ¨çš„ä¸¥é‡æ„ŸæŸ“ï¼Œç‰¹åˆ«æ˜¯æœ‰åŒ–è„“ä¸æ„ˆåˆï¼Œåˆå½¢æˆé€šé“æˆ–ç©ºæ´çš„æƒ…å†µã€‚\n",
       "\n",
       "ä»”ç»†æƒ³æƒ³ï¼Œæˆ‘æ€ä¹ˆæ„Ÿè§‰è¿™äº›ç—‡çŠ¶æ›´è´´è¿‘ç˜°ç–¬çš„è¡¨ç°ï¼Ÿå°¤å…¶è€ƒè™‘åˆ°å­©å­çš„å¹´çºªå’Œå¤å¤©å‘ç”Ÿçš„å­£èŠ‚æ€§å› ç´ ï¼Œæ¹¿çƒ­å¯èƒ½æ˜¯ä¸»å› ï¼Œä½†å¯èƒ½ä¹Ÿæœ‰ç«æ¯’æˆ–è€…ç—°æ¹¿é€ æˆçš„æ»ç•™ã€‚\n",
       "\n",
       "å›åˆ°åŸºæœ¬çš„ç—‡çŠ¶æè¿°ä¸Šçœ‹ï¼Œè¿™ç§é•¿æœŸä¸æ„ˆåˆåˆå¤æ‚çš„çŠ¶å†µï¼Œå¦‚æœç»“åˆä¸­åŒ»æ›´åé‡çš„ç—…åï¼Œæ˜¯ä¸æ˜¯æœ‰å¯èƒ½æ˜¯æ¶‰åŠæ›´æ·±å±‚æ¬¡çš„æ„ŸæŸ“ï¼Ÿ\n",
       "\n",
       "å†è€ƒè™‘ä¸€ä¸‹ï¼Œè¿™åº”è¯¥ä¸æ˜¯å•çº¯çš„ç˜°ç–¬ï¼Œå¾—ä»”ç»†åˆ†æå¤´çš®å¢åšå¹¶å‡ºç°ç©ºæ´è¿™æ ·çš„ä¸¥é‡ç—‡çŠ¶ã€‚ä¸­åŒ»é‡Œå¤´ï¼Œè¿™æ ·çš„è¡¨ç°å¯èƒ½æ›´ç¬¦åˆâ€˜èš€ç–®â€™æˆ–â€˜å¤´ç–½â€™ã€‚è¿™äº›ç—…åé€šå¸¸æè¿°å¤´éƒ¨ä¸¥é‡æ„ŸæŸ“åçš„æºƒçƒ‚å’Œç»„ç»‡åæ­»ã€‚\n",
       "\n",
       "çœ‹çœ‹å­£èŠ‚å’Œå­©å­çš„ä½“è´¨ï¼Œå¤å¤©åˆæ¹¿åˆçƒ­ï¼Œå¤–é‚ªå¾ˆå®¹æ˜“ä¾µå…¥å¤´éƒ¨ï¼Œå¯¹å­©å­è¿™ä¹ˆå¼±çš„å…ç–«ç³»ç»Ÿç®€ç›´å°±æ˜¯æŒ‘æˆ˜ã€‚å¤´ç–½è¿™ä¸ªç—…åå¬èµ·æ¥çœŸæ˜¯åˆ‡åˆï¼Œå› ä¸ºå®ƒæè¿°çš„æ„ŸæŸ“ä¸¥é‡ï¼Œæºƒçƒ‚åˆ°å‡ºç°ç©ºæ´ã€‚\n",
       "\n",
       "ä¸è¿‡ï¼Œä»”ç»†ç¢ç£¨åå‘ç°ï¼Œè¿˜æœ‰ä¸ªç—…åä¼¼ä¹æ›´ä¸ºåˆé€‚ï¼Œå«åšâ€˜è¼è›„ç––â€™ï¼Œè¿™ç—…åœ¨ä¸­åŒ»é‡Œä¸“æŒ‡åƒè¿™ç§ä¸¥é‡æ„ŸæŸ“å¹¶ä¼´æœ‰æ·±éƒ¨ç©ºæ´çš„æƒ…å†µã€‚å®ƒä¹Ÿæ¶µç›–äº†åŒ–è„“å’Œçš®è‚¤å¢åšè¿™äº›ç—‡çŠ¶ã€‚\n",
       "\n",
       "å“¦ï¼Œè¯¥ä¸ä¼šæ˜¯å¤å­£æ¹¿çƒ­ï¼Œå¯¼è‡´æ¹¿æ¯’å…¥ä¾µï¼Œå­©å­çš„ä½“è´¨ä¸èƒ½å¾¡ï¼Œå…¶ç—…æƒ…å‘å±•æˆè¿™æ ·çš„æ„ŸæŸ“ï¼Ÿç»¼åˆåˆ†æåæˆ‘è§‰å¾—â€˜è¼è›„ç––â€™è¿™ä¸ªç—…åçœŸæ˜¯ç›¸å½“ç¬¦åˆã€‚\n",
       "</think>\n",
       "ä»ä¸­åŒ»çš„è§’åº¦æ¥çœ‹ï¼Œä½ æ‰€æè¿°çš„ç—‡çŠ¶ç¬¦åˆâ€œè¼è›„ç––â€çš„ç—…ç—‡ã€‚è¿™ç§ç—…ç—‡é€šå¸¸å‘ç”Ÿåœ¨å¤´çš®ï¼Œè¡¨ç°ä¸ºå¤šå¤„ç»“èŠ‚ï¼Œæºƒç ´æµè„“ï¼Œå½¢æˆç©ºæ´ï¼Œæ‚£å¤„çš®è‚¤å¢åšä¸”é•¿æœŸä¸æ„ˆåˆã€‚æ¹¿çƒ­è¾ƒé‡çš„å¤å­£æ›´å®¹æ˜“å¯¼è‡´è¿™ç§ç—…ç—‡çš„å‘å±•ï¼Œç‰¹åˆ«æ˜¯åœ¨å…ç–«åŠ›è¾ƒå¼±çš„å„¿ç«¥èº«ä¸Šã€‚å»ºè®®ç»“åˆä¸­åŒ»çš„æ¸…çƒ­è§£æ¯’ã€ç¥›æ¹¿æ¶ˆè‚¿çš„æ²»ç–—æ–¹æ³•è¿›è¡Œå¤„ç†ï¼Œå¹¶é…åˆä¸“ä¸šçš„åŒ»ç–—å»ºè®®è¿›è¡Œè¯¦ç»†è¯Šæ–­å’Œæ²»ç–—ã€‚\n",
       "<ï½œendâ–ofâ–sentenceï½œ>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(dataset[0][\"text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. ä½¿ç”¨ Unsloth æ·»åŠ  LoRA é€‚é…å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T13:33:07.071960Z",
     "iopub.status.busy": "2025-08-31T13:33:07.071456Z",
     "iopub.status.idle": "2025-08-31T13:33:11.794285Z",
     "shell.execute_reply": "2025-08-31T13:33:11.793720Z",
     "shell.execute_reply.started": "2025-08-31T13:33:07.071935Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.8.5 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): Qwen2ForCausalLM(\n",
      "      (model): Qwen2Model(\n",
      "        (embed_tokens): Embedding(151936, 1536, padding_idx=151654)\n",
      "        (layers): ModuleList(\n",
      "          (0): Qwen2DecoderLayer(\n",
      "            (self_attn): Qwen2Attention(\n",
      "              (q_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=1536, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=1536, out_features=256, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=256, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=1536, out_features=256, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=256, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=1536, out_features=1536, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=1536, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): Qwen2MLP(\n",
      "              (gate_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1536, out_features=8960, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=8960, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1536, out_features=8960, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=8960, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=8960, out_features=1536, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=8960, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=1536, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
      "            (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
      "          )\n",
      "          (1-2): 2 x Qwen2DecoderLayer(\n",
      "            (self_attn): Qwen2Attention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1536, out_features=1536, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=1536, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1536, out_features=256, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=256, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1536, out_features=256, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=256, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1536, out_features=1536, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=1536, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): Qwen2MLP(\n",
      "              (gate_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=1536, out_features=8960, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=8960, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=1536, out_features=8960, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=8960, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=8960, out_features=1536, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=8960, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=1536, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
      "            (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
      "          )\n",
      "          (3-25): 23 x Qwen2DecoderLayer(\n",
      "            (self_attn): Qwen2Attention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1536, out_features=1536, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=1536, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1536, out_features=256, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=256, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1536, out_features=256, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=256, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1536, out_features=1536, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=1536, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): Qwen2MLP(\n",
      "              (gate_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1536, out_features=8960, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=8960, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1536, out_features=8960, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=8960, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=8960, out_features=1536, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=8960, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=1536, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
      "            (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
      "          )\n",
      "          (26): Qwen2DecoderLayer(\n",
      "            (self_attn): Qwen2Attention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1536, out_features=1536, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=1536, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1536, out_features=256, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=256, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1536, out_features=256, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=256, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1536, out_features=1536, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=1536, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): Qwen2MLP(\n",
      "              (gate_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=1536, out_features=8960, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=8960, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=1536, out_features=8960, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=8960, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=8960, out_features=1536, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=8960, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=1536, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
      "            (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
      "          )\n",
      "          (27): Qwen2DecoderLayer(\n",
      "            (self_attn): Qwen2Attention(\n",
      "              (q_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1536, out_features=1536, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=1536, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1536, out_features=256, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=256, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1536, out_features=256, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=256, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=1536, out_features=1536, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=1536, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (rotary_emb): LlamaRotaryEmbedding()\n",
      "            )\n",
      "            (mlp): Qwen2MLP(\n",
      "              (gate_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1536, out_features=8960, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=8960, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=1536, out_features=8960, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=1536, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=8960, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear4bit(\n",
      "                (base_layer): Linear4bit(in_features=8960, out_features=1536, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Identity()\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=8960, out_features=16, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=16, out_features=1536, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
      "            (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
      "          )\n",
      "        )\n",
      "        (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n",
      "        (rotary_emb): LlamaRotaryEmbedding()\n",
      "      )\n",
      "      (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# å› ä¸º `model` å¯¹è±¡ç°åœ¨æ˜¯ç”± Unsloth åˆ›å»ºçš„ï¼Œå®ƒåŒ…å«äº†æ‰€æœ‰å¿…éœ€çš„å±æ€§\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=16,\n",
    "    target_modules=[\n",
    "      \"q_proj\",\n",
    "      \"k_proj\",\n",
    "      \"v_proj\",\n",
    "      \"o_proj\",\n",
    "      \"gate_proj\",\n",
    "      \"up_proj\",\n",
    "      \"down_proj\",\n",
    "    ],\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    bias=\"none\",\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=1432,\n",
    "    use_rslora=False,\n",
    "    loftq_config=None,\n",
    ")\n",
    "# æ£€æŸ¥æ¨¡å‹ç»“æ„ï¼Œç¡®è®¤ LoRA é€‚é…å™¨å·²æ·»åŠ \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. é…ç½® SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T13:33:26.655871Z",
     "iopub.status.busy": "2025-08-31T13:33:26.655327Z",
     "iopub.status.idle": "2025-08-31T13:33:27.030866Z",
     "shell.execute_reply": "2025-08-31T13:33:27.030197Z",
     "shell.execute_reply.started": "2025-08-31T13:33:26.655846Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.119, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTConfig, SFTTrainer\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = SFTConfig(\n",
    "        per_device_train_batch_size = 64,\n",
    "        gradient_accumulation_steps = 2,\n",
    "        warmup_steps = 5,\n",
    "        # num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        max_steps = 60,\n",
    "        learning_rate = 2e-4,\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 1432,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. å¼€å§‹è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T13:33:41.450351Z",
     "iopub.status.busy": "2025-08-31T13:33:41.449839Z",
     "iopub.status.idle": "2025-08-31T13:47:36.201906Z",
     "shell.execute_reply": "2025-08-31T13:47:36.201214Z",
     "shell.execute_reply.started": "2025-08-31T13:33:41.450327Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 20,171 | Num Epochs = 1 | Total steps = 60\n",
      "O^O/ \\_/ \\    Batch size per device = 64 | Gradient accumulation steps = 2\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (64 x 2 x 1) = 128\n",
      " \"-____-\"     Trainable parameters = 18,464,768 of 1,795,552,768 (1.03% trained)\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 20,171 | Num Epochs = 1 | Total steps = 60\n",
      "O^O/ \\_/ \\    Batch size per device = 57 | Gradient accumulation steps = 2\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (57 x 2 x 1) = 114\n",
      " \"-____-\"     Trainable parameters = 18,464,768 of 1,795,552,768 (1.03% trained)\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 20,171 | Num Epochs = 1 | Total steps = 60\n",
      "O^O/ \\_/ \\    Batch size per device = 51 | Gradient accumulation steps = 2\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (51 x 2 x 1) = 102\n",
      " \"-____-\"     Trainable parameters = 18,464,768 of 1,795,552,768 (1.03% trained)\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 20,171 | Num Epochs = 1 | Total steps = 60\n",
      "O^O/ \\_/ \\    Batch size per device = 45 | Gradient accumulation steps = 2\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (45 x 2 x 1) = 90\n",
      " \"-____-\"     Trainable parameters = 18,464,768 of 1,795,552,768 (1.03% trained)\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 20,171 | Num Epochs = 1 | Total steps = 60\n",
      "O^O/ \\_/ \\    Batch size per device = 40 | Gradient accumulation steps = 2\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (40 x 2 x 1) = 80\n",
      " \"-____-\"     Trainable parameters = 18,464,768 of 1,795,552,768 (1.03% trained)\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 20,171 | Num Epochs = 1 | Total steps = 60\n",
      "O^O/ \\_/ \\    Batch size per device = 36 | Gradient accumulation steps = 2\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (36 x 2 x 1) = 72\n",
      " \"-____-\"     Trainable parameters = 18,464,768 of 1,795,552,768 (1.03% trained)\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 20,171 | Num Epochs = 1 | Total steps = 60\n",
      "O^O/ \\_/ \\    Batch size per device = 32 | Gradient accumulation steps = 2\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (32 x 2 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 18,464,768 of 1,795,552,768 (1.03% trained)\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 20,171 | Num Epochs = 1 | Total steps = 60\n",
      "O^O/ \\_/ \\    Batch size per device = 28 | Gradient accumulation steps = 2\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (28 x 2 x 1) = 56\n",
      " \"-____-\"     Trainable parameters = 18,464,768 of 1,795,552,768 (1.03% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2/60 : < :, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 20,171 | Num Epochs = 1 | Total steps = 60\n",
      "O^O/ \\_/ \\    Batch size per device = 25 | Gradient accumulation steps = 2\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (25 x 2 x 1) = 50\n",
      " \"-____-\"     Trainable parameters = 18,464,768 of 1,795,552,768 (1.03% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/60 05:28 < 02:27, 0.12 it/s, Epoch 0.10/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.214200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.143100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.106300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.185300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.071100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.977400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.931600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.794300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.852200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.851900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.848000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.644900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.760600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.476100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.587200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.599000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.491100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.498800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.452300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.480500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.399800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.433100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.403600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.305200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.338200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.424900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.360100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2.322600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.322000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.325200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>2.284200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2.306200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>2.330400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>2.305900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>2.248500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>2.318700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>2.352200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>2.292300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>2.350600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.268800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 20,171 | Num Epochs = 1 | Total steps = 60\n",
      "O^O/ \\_/ \\    Batch size per device = 22 | Gradient accumulation steps = 2\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (22 x 2 x 1) = 44\n",
      " \"-____-\"     Trainable parameters = 18,464,768 of 1,795,552,768 (1.03% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 07:05, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.329000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.284400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.253000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.257000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.370900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.256200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.144100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.262300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.135400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.219600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.309500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.315100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.193100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.204300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.256800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.070800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.223300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.227200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.202000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.164900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.212800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.272800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.236800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.203600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.236600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.237800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>2.150800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>2.175400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.282500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.234300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>2.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2.222100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>2.168500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>2.217000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>2.178400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>2.177000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>2.178500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>2.192100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>2.201300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.147800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>2.178700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>2.272200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>2.164000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>2.259700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>2.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>2.238800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>2.212100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>2.238400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>2.115100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.172700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>2.242100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>2.221400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>2.134100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>2.167400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>2.143000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>2.184200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>2.204500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>2.203800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>2.257000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.216100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainOutput(global_step=60, training_loss=2.2135083158810933, metrics={'train_runtime': 433.3618, 'train_samples_per_second': 6.092, 'train_steps_per_second': 0.138, 'total_flos': 2.2651084149264384e+16, 'train_loss': 2.2135083158810933})\n"
     ]
    }
   ],
   "source": [
    "trainer_stats = trainer.train()\n",
    "\n",
    "# æ‰“å°è®­ç»ƒç»Ÿè®¡ä¿¡æ¯\n",
    "print(trainer_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. ä¿å­˜å¾®è°ƒåçš„æ¨¡å‹ï¼ˆLoraï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T13:47:41.482907Z",
     "iopub.status.busy": "2025-08-31T13:47:41.482247Z",
     "iopub.status.idle": "2025-08-31T13:47:42.185612Z",
     "shell.execute_reply": "2025-08-31T13:47:42.184964Z",
     "shell.execute_reply.started": "2025-08-31T13:47:41.482885Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"qwen-1.5b_lora_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T13:47:42.186896Z",
     "iopub.status.busy": "2025-08-31T13:47:42.186525Z",
     "iopub.status.idle": "2025-08-31T13:47:42.308090Z",
     "shell.execute_reply": "2025-08-31T13:47:42.307502Z",
     "shell.execute_reply.started": "2025-08-31T13:47:42.186875Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('qwen-1.5b_lora_model/tokenizer_config.json',\n",
       " 'qwen-1.5b_lora_model/special_tokens_map.json',\n",
       " 'qwen-1.5b_lora_model/chat_template.jinja',\n",
       " 'qwen-1.5b_lora_model/tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"qwen-1.5b_lora_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T13:47:51.409302Z",
     "iopub.status.busy": "2025-08-31T13:47:51.408781Z",
     "iopub.status.idle": "2025-08-31T13:47:51.412057Z",
     "shell.execute_reply": "2025-08-31T13:47:51.411487Z",
     "shell.execute_reply.started": "2025-08-31T13:47:51.409279Z"
    }
   },
   "outputs": [],
   "source": [
    "# æ¨¡å‹ä¿å­˜æ–¹å¼äºŒé€‰ä¸€ï¼ˆè¦ä¹ˆä½¿ç”¨ä¸Šé¢çš„åˆ†å¼€ä¿å­˜ï¼Œè¦ä¹ˆä½¿ç”¨è¿™é‡Œçš„åˆå¹¶ Lora ä¿å­˜ï¼‰\n",
    "# model.save_pretrained_merged(\"qwen-1.5b_lora_model\", tokenizer, save_method=\"merged_16bit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. æµ‹è¯•è®­ç»ƒåçš„ç”Ÿæˆç»“æœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T13:47:53.639070Z",
     "iopub.status.busy": "2025-08-31T13:47:53.638345Z",
     "iopub.status.idle": "2025-08-31T13:48:26.621458Z",
     "shell.execute_reply": "2025-08-31T13:48:26.620841Z",
     "shell.execute_reply.started": "2025-08-31T13:47:53.639047Z"
    }
   },
   "outputs": [],
   "source": [
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "\n",
    "question=\"ä¸€ä¸ªæ‚£æœ‰æ€¥æ€§é˜‘å°¾ç‚çš„ç—…äººå·²ç»å‘ç—…5å¤©ï¼Œè…¹ç—›ç¨æœ‰å‡è½»ä½†ä»ç„¶å‘çƒ­ï¼Œåœ¨ä½“æ£€æ—¶å‘ç°å³ä¸‹è…¹æœ‰å‹ç—›çš„åŒ…å—ï¼Œæ­¤æ—¶åº”å¦‚ä½•å¤„ç†ï¼Ÿ\", # Question\n",
    "inputs = tokenizer([inference_prompt.format(question, \"\")], return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids=inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    max_new_tokens=1000,\n",
    "    use_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T13:48:26.623061Z",
     "iopub.status.busy": "2025-08-31T13:48:26.622457Z",
     "iopub.status.idle": "2025-08-31T13:48:26.627085Z",
     "shell.execute_reply": "2025-08-31T13:48:26.626581Z",
     "shell.execute_reply.started": "2025-08-31T13:48:26.623039Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<think>\n",
      "è¿™ä¸ªç—…äººå·²ç»5å¤©äº†ï¼Œæ€¥æ€§é˜‘å°¾ç‚ï¼Œè¿˜æœ‰ä¸€ç‚¹å‘çƒ­ã€‚å—¯ï¼Œçœ‹åˆ°è¿™ä¸ªç—…äººï¼Œæˆ‘å…ˆæƒ³åˆ°çš„æ˜¯åº”è¯¥å¤„ç†ä»–çš„ç—‡çŠ¶ï¼Œæ¯”å¦‚è®©ä»–çš„ç–¼ç—›å‡è½»ï¼ŒåŒæ—¶çœ‹çœ‹æ˜¯å¦èƒ½è®©ä»–ä¸è¦å‘çƒ­ã€‚\n",
      "\n",
      "å—¯ï¼Œç—…äººæœ‰å‹ç—›åŒ…å—ï¼Œè¿™å¯èƒ½æ˜¯é˜‘å°¾ç‚å¯¼è‡´çš„ï¼Œå› ä¸ºå‹ç—›åŒ…å—é€šå¸¸å’Œé˜‘å°¾ç‚æœ‰å…³ã€‚è€Œä¸”ï¼Œä»–å‘çƒ­äº†ï¼Œå¯èƒ½éœ€è¦ä¸€äº›è¯ç‰©æ¥ç¼“è§£å‘çƒ­ï¼Œæ¯”å¦‚å¯¹ä¹™é…°æ°¨åŸºé…šã€‚\n",
      "\n",
      "ä¸è¿‡ï¼Œæˆ‘å¾—æƒ³æƒ³ï¼Œå¦‚æœä»–æœ‰å‹ç—›åŒ…å—ï¼Œå¯èƒ½ä¼šå¯¼è‡´ç–¼ç—›åŠ é‡ï¼Œç”šè‡³è®©ä»–çš„èº«ä½“å¤±å»å¹³è¡¡ã€‚è¿™æ ·ï¼Œè¯ç‰©å¯èƒ½éœ€è¦æ›´è°¨æ…åœ°ä½¿ç”¨ï¼Œä¸èƒ½éšä¾¿ç”¨ã€‚\n",
      "\n",
      "å—¯ï¼Œæƒ³æƒ³çœ‹ï¼Œå¦‚æœç—…äººæœ‰å‹ç—›åŒ…å—ï¼Œæœ€å¥½å…ˆç”¨ä¸€äº›æ­¢ç—›è¯ï¼Œæ¯”å¦‚å·¦æ—‹æ›²è‹·ï¼Œè¿™æ ·èƒ½å‡å°‘ç–¼ç—›ã€‚åŒæ—¶ï¼Œè¦å°å¿ƒä¸è¦è®©ä»–çš„ç–¼ç—›å¤ªå¤§ï¼Œä»¥å…åŠ é‡å‹ç—›åŒ…å—ã€‚\n",
      "\n",
      "ç„¶åï¼Œå†æƒ³æƒ³ï¼Œä»–å‘çƒ­äº†ï¼Œå¯èƒ½éœ€è¦ä¸€äº›é€€ç«è¯ç‰©ï¼Œæ¯”å¦‚å¯¹ä¹™é…°æ°¨åŸºé…šã€‚ä¸è¿‡ï¼Œè¦å°å¿ƒä¸èƒ½ç”¨å¾—å¤ªå¿«ï¼Œå¦åˆ™ä¼šåˆºæ¿€ç–¼ç—›ï¼Œç”šè‡³å¼•èµ·è¯ç‰©ååº”ã€‚\n",
      "\n",
      "å—¯ï¼Œçœ‹æ¥è¿™ä¸ªç—…äººåº”è¯¥å…ˆç”¨å·¦æ—‹æ›²è‹·æ¥ç¼“è§£ç–¼ç—›ï¼Œç„¶åæ…¢æ…¢åŠ è¯ï¼ŒåŒæ—¶æ³¨æ„è¯ç‰©çš„ä½¿ç”¨ï¼Œé˜²æ­¢å½±å“åˆ°ä»–çš„ç–¼ç—›å’Œå‘çƒ­ã€‚\n",
      "\n",
      "æ‰€ä»¥ï¼Œæˆ‘è§‰å¾—å¯¹ä¹™é…°æ°¨åŸºé…šåº”è¯¥å…ˆåŠ æ…¢ä¸€ç‚¹ï¼Œè¿™æ ·å¯ä»¥é¿å…è¯ç‰©çš„å‰¯ä½œç”¨ï¼ŒåŒæ—¶ç¡®ä¿ç–¼ç—›å‡è½»å’Œå‘çƒ­çš„æ§åˆ¶ã€‚\n",
      "\n",
      "å—¯ï¼Œç°åœ¨çœ‹æ¥ï¼Œè¿™ä¸ªç—…äººåº”è¯¥å…ˆåŠ æ…¢å¯¹ä¹™é…°æ°¨åŸºé…šï¼Œå†æ…¢æ…¢å¢åŠ ï¼ŒåŒæ—¶ä½¿ç”¨å·¦æ—‹æ›²è‹·æ¥ç¼“è§£ç–¼ç—›ï¼Œè¿™æ ·å¯ä»¥æ›´å®‰å…¨åœ°å¤„ç†ä»–çš„ç—‡çŠ¶ã€‚è¿™æ ·ï¼Œä»–åº”è¯¥èƒ½æ›´å¥½åœ°åº”å¯¹è¿™äº›ç—‡çŠ¶ã€‚\n",
      "</think>\n",
      "å¯¹äºä¸€ä¸ªå·²ç»å‘ç—…5å¤©çš„æ€¥æ€§é˜‘å°¾ç‚æ‚£è€…ï¼Œå‡ºç°å³ä¸‹è…¹æœ‰å‹ç—›åŒ…å—ä¸”å‘çƒ­çš„æƒ…å†µï¼Œå»ºè®®é‡‡å–ä»¥ä¸‹æ­¥éª¤ï¼š\n",
      "\n",
      "1. **è¯„ä¼°ç–¼ç—›å’Œå‘çƒ­æƒ…å†µ**ï¼šé¦–å…ˆç¡®è®¤å‹ç—›åŒ…å—æ˜¯å¦åˆç†ï¼Œå¹¶è¯„ä¼°ç–¼ç—›å’Œå‘çƒ­çš„ä¸¥é‡ç¨‹åº¦ã€‚è¿™äº›ç—‡çŠ¶å¯èƒ½éœ€è¦è¯ç‰©çš„é€‚å½“ç¼“è§£ã€‚\n",
      "\n",
      "2. **é€‰æ‹©è¯ç‰©**ï¼šä½¿ç”¨å·¦æ—‹æ›²è‹·ä½œä¸ºæ­¢ç—›è¯ï¼Œå¯ä»¥å‡è½»ç–¼ç—›ï¼Œä½†éœ€åœ¨ä½¿ç”¨å‰è°¨æ…ï¼Œå› ä¸ºè¿™å¯èƒ½å¼•èµ·ç–¼ç—›åŠ é‡ã€‚\n",
      "\n",
      "3. **ç¼“æ…¢ç”¨è¯**ï¼šå¯¹ä¹™é…°æ°¨åŸºé…šçš„ä½¿ç”¨è¦ç¼“æ…¢ï¼Œä»¥é¿å…åˆºæ¿€ç–¼ç—›ï¼Œå¹¶æ§åˆ¶å…¶å½±å“ã€‚é€šå¸¸åœ¨åŒ»ç”ŸæŒ‡å¯¼ä¸‹ä½¿ç”¨ï¼Œé¿å…è¶…é‡ä½¿ç”¨ã€‚\n",
      "\n",
      "4. **åŒæ—¶æ§åˆ¶å‘çƒ­**ï¼šåœ¨å¯¹ä¹™é…°æ°¨åŸºé…šçš„ä½¿ç”¨è¿‡ç¨‹ä¸­ï¼Œåº”å°å¿ƒæ§åˆ¶å…¶å‰‚é‡ï¼Œé¿å…å¯¼è‡´å‘çƒ­å¢åŠ æˆ–è¯ç‰©ååº”ã€‚å¯ä½¿ç”¨é€€ç«è¯å¦‚å¯¹ä¹™é…°æ°¨åŸºé…šï¼Œä½†éœ€æ ¹æ®æ‚£è€…çš„æƒ…å†µè°ƒæ•´ç”¨è¯é‡ã€‚\n",
      "\n",
      "5. **è§‚å¯Ÿç—‡çŠ¶å˜åŒ–**ï¼šåœ¨å¼€å§‹ä½¿ç”¨è¯ç‰©åï¼ŒæŒç»­è§‚å¯Ÿæ‚£è€…ç—‡çŠ¶å˜åŒ–ï¼Œå¿…è¦æ—¶è°ƒæ•´ç”¨è¯æ–¹æ¡ˆï¼Œä»¥ç¡®ä¿ç–¼ç—›å‡è½»å’Œå‘çƒ­çš„ç¨³å®šã€‚\n",
      "\n",
      "6. **åŒ»ç–—å»ºè®®**ï¼šåœ¨åŒ»ç”Ÿçš„æŒ‡å¯¼ä¸‹ï¼Œæ ¹æ®æ‚£è€…çš„å…·ä½“æƒ…å†µè°ƒæ•´ç”¨è¯æ–¹æ¡ˆï¼Œå¹¶åœ¨æ‚£è€…ç—…æƒ…ç¨³å®šåå†è¿›è¡Œæ›´å…¨é¢çš„æ²»ç–—ã€‚\n",
      "\n",
      "å»ºè®®åœ¨æ‚£è€…ç—‡çŠ¶æŒç»­æ—¶ï¼Œé€æ­¥è°ƒæ•´ç”¨è¯ï¼ŒåŒæ—¶å¯†åˆ‡è§‚å¯Ÿç—‡çŠ¶å˜åŒ–ï¼Œä»¥ç¡®ä¿è¯ç‰©çš„ä½¿ç”¨å®‰å…¨æ€§å’Œæœ‰æ•ˆæ€§ã€‚å¦‚æœç—‡çŠ¶æŒç»­åŠ é‡æˆ–å‡ºç°å…¶ä»–ä¸é€‚ï¼ŒåŠæ—¶å°±åŒ»è¿›è¡Œè¿›ä¸€æ­¥æ£€æŸ¥å’Œæ²»ç–—ã€‚\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "print(output[0].split(\"### Response:\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T13:48:26.628070Z",
     "iopub.status.busy": "2025-08-31T13:48:26.627687Z",
     "iopub.status.idle": "2025-08-31T13:48:26.650361Z",
     "shell.execute_reply": "2025-08-31T13:48:26.649847Z",
     "shell.execute_reply.started": "2025-08-31T13:48:26.628052Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_response(question: str, model, tokenizer, inference_prompt: str, max_new_tokens: int = 1024) -> str:\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹å’Œåˆ†è¯å™¨ä¸ºç»™å®šçš„åŒ»å­¦é—®é¢˜ç”Ÿæˆå“åº”ã€‚\n",
    "\n",
    "    Args:\n",
    "        question (str): éœ€è¦æ¨¡å‹å›ç­”çš„åŒ»å­¦é—®é¢˜ã€‚\n",
    "        model: å·²åŠ è½½çš„ Unsloth/Hugging Face æ¨¡å‹ã€‚\n",
    "        tokenizer: å¯¹åº”çš„åˆ†è¯å™¨ã€‚\n",
    "        inference_prompt (str): ç”¨äºæ ¼å¼åŒ–è¾“å…¥çš„ f-string æ¨¡æ¿ã€‚\n",
    "        max_new_tokens (int, optional): ç”Ÿæˆå“åº”çš„æœ€å¤§ token æ•°é‡ã€‚é»˜è®¤ä¸º 1024ã€‚\n",
    "\n",
    "    Returns:\n",
    "        str: æ¨¡å‹ç”Ÿæˆçš„å“åº”æ–‡æœ¬ï¼Œå·²å»é™¤ prompt éƒ¨åˆ†ã€‚\n",
    "    \"\"\"\n",
    "    # 1. ä½¿ç”¨æ¨¡æ¿æ ¼å¼åŒ–è¾“å…¥\n",
    "    prompt = inference_prompt.format(\n",
    "        question, # å¡«å……é—®é¢˜\n",
    "        \"\",       # ç•™ç©ºï¼Œè®©æ¨¡å‹ç”Ÿæˆ CoT å’Œ Response\n",
    "    )\n",
    "\n",
    "    # 2. å°†æ ¼å¼åŒ–åçš„ prompt è¿›è¡Œåˆ†è¯ï¼Œå¹¶è½¬ç§»åˆ° GPU\n",
    "    inputs = tokenizer([prompt], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # 3. ä½¿ç”¨æ¨¡å‹ç”Ÿæˆè¾“å‡º\n",
    "    # use_cache=True ç”¨äºåŠ é€Ÿè§£ç è¿‡ç¨‹\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs.input_ids,\n",
    "        attention_mask=inputs.attention_mask,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        use_cache=True,\n",
    "    )\n",
    "    \n",
    "    # 4. å°†ç”Ÿæˆçš„ token è§£ç ä¸ºæ–‡æœ¬\n",
    "    # skip_special_tokens=True ä¼šç§»é™¤åƒ EOS_TOKEN è¿™æ ·çš„ç‰¹æ®Šæ ‡è®°\n",
    "    decoded_output = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "\n",
    "    # 5. åˆ‡åˆ†å­—ç¬¦ä¸²ï¼Œåªè¿”å› \"### Response:\" ä¹‹åçš„éƒ¨åˆ†\n",
    "    # ä½¿ç”¨ .split() åˆ†å‰²å¹¶è·å–å“åº”å†…å®¹ï¼Œ.strip() ç”¨äºå»é™¤å¯èƒ½å­˜åœ¨çš„å‰åç©ºç™½å­—ç¬¦\n",
    "    response_part = decoded_output.split(\"### Response:\")\n",
    "    if len(response_part) > 1:\n",
    "        return response_part[1].strip()\n",
    "    else:\n",
    "        # å¦‚æœæ¨¡å‹æ²¡æœ‰ç”Ÿæˆ \"### Response:\" æ ‡è®°ï¼Œåˆ™è¿”å›æ•´ä¸ªç”Ÿæˆå†…å®¹ä»¥ä¾›è°ƒè¯•\n",
    "        return decoded_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T13:48:26.651636Z",
     "iopub.status.busy": "2025-08-31T13:48:26.651266Z",
     "iopub.status.idle": "2025-08-31T13:48:53.951620Z",
     "shell.execute_reply": "2025-08-31T13:48:53.951012Z",
     "shell.execute_reply.started": "2025-08-31T13:48:26.651617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== æ¨¡å‹å›ç­” ====================\n",
      "<think>\n",
      "è¿™ä¸ª60å²çš„æ‚£è€…ï¼Œä»–çš„å³ä¾§èƒ¸ç–¼è®©æˆ‘å¾ˆå›°æ‰°ã€‚Xçº¿æ£€æŸ¥æ˜¾ç¤ºå³ä¾§è‚‹è†ˆè§’æ¶ˆå¤±ï¼Œè¿™è®©æˆ‘æƒ³åˆ°äº†è‚ºç»“æ ¸ï¼Œä½†èƒ¸è…”é‡Œæœ‰ç§¯æ¶²ï¼Œè¿™ä¼¼ä¹æœ‰ç‚¹ä¸å¯¹åŠ²ã€‚é€šå¸¸ï¼Œè‚ºç»“æ ¸ä¼šæœ‰èƒ¸è…”ç§¯æ¶²ï¼Œä½†å…·ä½“æ€§è´¨å‘¢ï¼Ÿå—¯ï¼Œå¯èƒ½æ˜¯ç»“æ ¸ç—…ï¼Œä¹Ÿå¯èƒ½æœ‰å…¶ä»–åŸå› ã€‚\n",
      "\n",
      "æˆ‘ä»¬å¾—å¼„æ¸…æ¥šè¿™ä¸ªç§¯æ¶²åˆ°åº•æ˜¯ä»€ä¹ˆç±»å‹çš„ã€‚å¦‚æœèƒ¸è…”ç§¯æ¶²æ˜¯ç»“æ ¸ç—…å¼•èµ·çš„ï¼Œé‚£å®ƒåº”è¯¥å±äºç»“æ ¸æ€§èƒ¸è…”ç§¯æ¶²ã€‚å¯æ˜¯ï¼Œå¦‚æœæ˜¯å…¶ä»–åŸå› å¯¼è‡´çš„ï¼Œæ¯”å¦‚è‚ºç»“æ ¸å¯èƒ½ä¹Ÿä¼šæœ‰å…¶ä»–è¡¨ç°ã€‚å—¯ï¼Œæ‰€ä»¥å¯èƒ½éœ€è¦è¿›ä¸€æ­¥çš„æ£€éªŒæ¥ç¡®è®¤ã€‚\n",
      "\n",
      "æˆ‘è®°å¾—åœ¨è¯Šæ–­ç»“æ ¸çš„æ—¶å€™ï¼Œé€šå¸¸ä¼šè¿›è¡Œèƒ¸è…”çš„æ´»æ£€ï¼Œçœ‹èƒ¸è…”é‡Œæœ‰æ²¡æœ‰ç»“æ ¸æ€§èƒ¸è…”ç§¯æ¶²ã€‚å¦‚æœç»“æœæ˜¯è‚¯å®šçš„ï¼Œé‚£æˆ‘ä»¬å°±å¯ä»¥æ˜ç¡®è¯Šæ–­äº†ã€‚æ‰€ä»¥ï¼Œå¦‚æœèƒ¸è…”ç§¯æ¶²æ˜¯ç»“æ ¸æ€§çš„è¯ï¼Œæ´»æ£€æ˜¯ä¸ªå¥½é€‰æ‹©ã€‚ä½†æ˜¯ï¼Œå¦‚æœä¸ç¡®å®šæ˜¯ä¸æ˜¯ç»“æ ¸æ€§çš„è¯ï¼Œå¯èƒ½ä¼šé€‰æ‹©å…¶ä»–æ–¹æ³•ï¼Œæ¯”å¦‚ç»“æ ¸ç—…çš„è¾…åŠ©æ£€æŸ¥ã€‚\n",
      "\n",
      "æ‰€ä»¥ï¼Œå¦‚æœèƒ¸è…”ç§¯æ¶²æ˜¯ç»“æ ¸ç—…ï¼Œæ´»æ£€æ˜¯ä¸ªä¸é”™çš„é€‰æ‹©ã€‚å¦‚æœä¸ç¡®å®šï¼Œå¯èƒ½éœ€è¦æ£€æŸ¥å…¶ä»–å› ç´ ï¼Œæ¯”å¦‚ç»“æ ¸ç—…çš„è¾…åŠ©æ£€æŸ¥ã€‚è¿™è®©æˆ‘æƒ³åˆ°ï¼Œè¿™å¯èƒ½æ¶‰åŠåˆ°å¯¹æ‚£è€…è¿›è¡Œæ›´å…¨é¢çš„æ£€æŸ¥ï¼Œä»¥ç¡®ä¿æˆ‘ä»¬èƒ½å‡†ç¡®åœ°è¯Šæ–­å‡ºåŸå› ã€‚\n",
      "\n",
      "å“¦ï¼Œå¯¹äº†ï¼Œç»“æ ¸ç—…çš„è¾…åŠ©æ£€æŸ¥åŒ…æ‹¬ç»“æ ¸ç—…çš„èƒ¸è…”æ´»æ£€å’Œç»“æ ¸ç—…çš„ä½“æ ¼æ£€æŸ¥ã€‚å¦‚æœè¦ç¡®è®¤æ˜¯ç»“æ ¸æ€§èƒ¸è…”ç§¯æ¶²ï¼Œç»“æ ¸ç—…çš„èƒ¸è…”æ´»æ£€æ˜¯å…³é”®ã€‚å¦‚æœä¸ç¡®å®šï¼Œå¯èƒ½éœ€è¦ç»“åˆå…¶ä»–æ£€æŸ¥ç»“æœï¼Œæ¯”å¦‚ç»“æ ¸ç—…çš„ä½“æ ¼æ£€æŸ¥ï¼Œæ¥å…¨é¢äº†è§£æ‚£è€…çš„æƒ…å†µã€‚\n",
      "\n",
      "æ‰€ä»¥ï¼Œæœ€ç»ˆï¼Œå¦‚æœç¡®å®šæ˜¯è‚ºç»“æ ¸ï¼Œé‚£ä¹ˆç»“æ ¸ç—…çš„èƒ¸è…”æ´»æ£€æ˜¯ä¸ªå¥½æ–¹æ³•ã€‚å¦‚æœä¸ç¡®å®šï¼Œå¯èƒ½éœ€è¦ç»“åˆå…¶ä»–è¾…åŠ©æ£€æŸ¥ï¼Œä»¥ç¡®ä¿æˆ‘ä»¬èƒ½å‡†ç¡®åœ°è¯Šæ–­å‡ºç—…å› ã€‚è¿™è®©æˆ‘è§‰å¾—ï¼Œé€‰æ‹©åˆé€‚çš„å®éªŒå®¤æ£€æŸ¥éå¸¸é‡è¦ï¼Œä»¥å¸®åŠ©æˆ‘ä»¬å¿«é€Ÿå®šä½å’Œè¯Šæ–­å‡ºæ‚£è€…çš„ç—…å› ã€‚\n",
      "</think>\n",
      "å¯¹äºè¯¥60å²ç”·æ€§æ‚£è€…çš„æƒ…å†µï¼Œé¦–å…ˆéœ€è¦æ˜ç¡®èƒ¸è…”ç§¯æ¶²çš„æ€§è´¨ã€‚å¦‚æœèƒ¸è…”ç§¯æ¶²æ˜¯ç»“æ ¸æ€§ï¼Œé‚£ä¹ˆé€‰æ‹©ç»“æ ¸ç—…çš„èƒ¸è…”æ´»æ£€æ˜¯ä¸ªæœ‰æ•ˆçš„æ–¹æ³•ï¼Œä»¥ç¡®å®šè¯Šæ–­ã€‚å¦‚æœä¸ç¡®å®šæ˜¯ç»“æ ¸æ€§èƒ¸è…”ç§¯æ¶²ï¼Œé€šå¸¸ä¼šç»“åˆç»“æ ¸ç—…çš„è¾…åŠ©æ£€æŸ¥ï¼Œå¦‚ç»“æ ¸ç—…çš„ä½“æ ¼æ£€æŸ¥ï¼Œä»¥å…¨é¢äº†è§£æ‚£è€…ç—…å› ã€‚å› æ­¤ï¼Œé’ˆå¯¹è¯¥æ‚£è€…çš„æƒ…å†µï¼Œå»ºè®®é€‰æ‹©ç»“æ ¸ç—…çš„èƒ¸è…”æ´»æ£€æ¥ç¡®å®šèƒ¸è…”ç§¯æ¶²çš„æ€§è´¨ã€‚\n"
     ]
    }
   ],
   "source": [
    "my_question = \"å¯¹äºä¸€å60å²ç”·æ€§æ‚£è€…ï¼Œå‡ºç°å³ä¾§èƒ¸ç–¼å¹¶åœ¨Xçº¿æ£€æŸ¥ä¸­æ˜¾ç¤ºå³ä¾§è‚‹è†ˆè§’æ¶ˆå¤±ï¼Œè¯Šæ–­ä¸ºè‚ºç»“æ ¸ä¼´å³ä¾§èƒ¸è…”ç§¯æ¶²ï¼Œè¯·é—®å“ªä¸€é¡¹å®éªŒå®¤æ£€æŸ¥å¯¹äº†è§£èƒ¸æ°´çš„æ€§è´¨æ›´æœ‰å¸®åŠ©ï¼Ÿ\"\n",
    "\n",
    "response = generate_response(my_question, model, tokenizer, inference_prompt)\n",
    "print(\"==================== æ¨¡å‹å›ç­” ====================\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T13:48:53.952424Z",
     "iopub.status.busy": "2025-08-31T13:48:53.952199Z",
     "iopub.status.idle": "2025-08-31T13:49:10.584955Z",
     "shell.execute_reply": "2025-08-31T13:49:10.584356Z",
     "shell.execute_reply.started": "2025-08-31T13:48:53.952406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== æ¨¡å‹å›ç­” ====================\n",
      "<think>\n",
      "å—¯ï¼Œè¿™ä½28å²çš„ç”·æ€§æ‚£è€…æœ€è¿‘å·¥ä½œæ˜¯ç¨‹åºå‘˜ï¼Œè€Œä¸”ç»å¸¸ç†¬å¤œï¼Œè¿™è®©æˆ‘æƒ³åˆ°ï¼Œå¯èƒ½æ˜¯ç¥ç»è¡°ç«­çš„è¿¹è±¡ã€‚å› ä¸ºç»å¸¸ç†¬å¤œå¯èƒ½ä¼šå¯¼è‡´ç¥ç»çš„ç–²åŠ³ï¼Œä»è€Œå¼•å‘ä¸€äº›ç¥ç»ç³»ç»Ÿçš„é—®é¢˜ã€‚\n",
      "\n",
      "ä½†æ˜¯ï¼Œç°åœ¨ä»–åˆæ„Ÿè§‰å¤´æ™•ç›®çœ©ï¼Œç”šè‡³æœ‰ç‚¹æ¶å¿ƒï¼Œè¿™è®©æˆ‘æƒ³åˆ°æ›´å¤æ‚çš„æƒ…å†µã€‚å¤´æ™•ç›®çœ©ï¼Œæ¶å¿ƒï¼Œè¿™äº›ç—‡çŠ¶éƒ½å¯èƒ½å’Œè„‘åŠ›æ´»åŠ¨æœ‰å…³ï¼Œå°¤å…¶æ˜¯é•¿æ—¶é—´çš„ç¥ç»åˆºæ¿€ã€‚\n",
      "\n",
      "å†æƒ³æƒ³ï¼Œè„‘åŠ›æ´»åŠ¨æ˜¯ç¨‹åºå‘˜çš„ä¸»è¦å·¥ä½œï¼Œé•¿æ—¶é—´çš„ç¥ç»åˆºæ¿€å°±å¯èƒ½è®©è„‘ä¾›è¡€ä¸è¶³ï¼Œä»è€Œå¯¼è‡´è„‘ä¾›è¡€ä¸è¶³ï¼Œè¿›è€Œå¼•å‘è„‘ä¾›è¡€ä¸è¶³å¯¼è‡´çš„è„‘å’ä¸­ã€‚è„‘å’ä¸­çš„ç—‡çŠ¶åŒ…æ‹¬æ™•å¥ã€æ¶å¿ƒã€å¤´æ™•ï¼Œè¿™äº›éƒ½ä¸è„‘ä¾›è¡€ä¸è¶³æœ‰å…³ã€‚\n",
      "\n",
      "æ‰€ä»¥ï¼Œç»“åˆä»–çš„å·¥ä½œå’Œç—‡çŠ¶ï¼Œè„‘å’ä¸­çš„å¯èƒ½æ€§æ¯”è¾ƒé«˜ã€‚è„‘å’ä¸­çš„ç—…å› ä¸»è¦æ˜¯è„‘ä¾›è¡€ä¸è¶³ï¼Œè€Œé•¿æ—¶é—´çš„è„‘åŠ›æ´»åŠ¨å’Œç¥ç»åˆºæ¿€å°±æ˜¯å¯¼è‡´ä¾›è¡€ä¸è¶³çš„åŸå› ã€‚\n",
      "\n",
      "æ‰€ä»¥ï¼Œç»¼åˆæ¥çœ‹ï¼Œè¿™ä½28å²ç”·æ€§æ‚£è€…çš„æƒ…å†µå¾ˆå¯èƒ½æ˜¯è„‘å’ä¸­çš„è¡¨ç°ã€‚å†ä»”ç»†æƒ³æƒ³ï¼Œè„‘å’ä¸­çš„ç—…å› ç¡®å®è·Ÿè„‘ä¾›è¡€ä¸è¶³æœ‰å…³ï¼Œè€Œè¿™ç§ç—‡çŠ¶ä¹Ÿç¬¦åˆä»–çš„å·¥ä½œå’Œç—‡çŠ¶è¡¨ç°ã€‚å› æ­¤ï¼Œè¿™åº”è¯¥æ˜¯è„‘å’ä¸­çš„ä¸€ä¸ªå¯èƒ½çš„åŸå› ã€‚\n",
      "</think>\n",
      "è¿™ä½28å²çš„ç”·æ€§æ‚£è€…æœ€è¿‘å·¥ä½œæ˜¯ç¨‹åºå‘˜ï¼Œé•¿æœŸç†¬å¤œï¼Œç—‡çŠ¶åŒ…æ‹¬å¤´æ™•ç›®çœ©å’Œæ¶å¿ƒï¼Œè¿™æç¤ºå¯èƒ½æœ‰è„‘å’ä¸­çš„ç—‡çŠ¶ã€‚è„‘å’ä¸­çš„ç—…å› ä¸»è¦æ˜¯è„‘ä¾›è¡€ä¸è¶³ï¼Œè€Œè¿™ç§ç—‡çŠ¶ä¹Ÿä¸è„‘åŠ›æ´»åŠ¨å’Œç¥ç»åˆºæ¿€æœ‰å…³ã€‚ç”±äºæ‚£è€…é•¿æœŸçš„è„‘åŠ›æ´»åŠ¨ï¼Œè„‘ä¾›è¡€ä¸è¶³æˆä¸ºå¯èƒ½çš„åŸå› ï¼Œå› æ­¤ï¼Œè¿™å¯èƒ½æ˜¯è„‘å’ä¸­çš„è¡¨ç°ã€‚\n"
     ]
    }
   ],
   "source": [
    "my_question = \"å¯¹äºä¸€å 28 å²çš„ç”·æ€§æ‚£è€…ï¼Œå·¥ä½œæ˜¯ç¨‹åºå‘˜ï¼Œå¸¸å¹´ç†¬å¤œï¼Œæœ€è¿‘çªç„¶æ„Ÿè§‰å¤´æ™•ç›®çœ©ï¼Œç”šè‡³æœ‰ç‚¹æ¶å¿ƒã€‚è¯·é—®æœ‰å¯èƒ½æ˜¯ä»€ä¹ˆç–¾ç—…ï¼Ÿ\"\n",
    "\n",
    "response = generate_response(my_question, model, tokenizer, inference_prompt)\n",
    "print(\"==================== æ¨¡å‹å›ç­” ====================\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.åŠ è½½å¾®è°ƒå‰æ¨¡å‹è¿›è¡Œå¯¹æ¯”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿™ä¸€æ­¥ä¼šè¿”å›ä¸€ä¸ªç»è¿‡ Unsloth ä¼˜åŒ–çš„æ¨¡å‹å’Œä¸€ä¸ªåˆ†è¯å™¨\n",
    "model_sft_before, tokenizer_sft_before = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_name,\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T13:53:58.772940Z",
     "iopub.status.busy": "2025-08-31T13:53:58.772483Z",
     "iopub.status.idle": "2025-08-31T13:54:37.799401Z",
     "shell.execute_reply": "2025-08-31T13:54:37.798823Z",
     "shell.execute_reply.started": "2025-08-31T13:53:58.772919Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== æ¨¡å‹å›ç­” ====================\n",
      "<think>\n",
      "å—¯ï¼Œæˆ‘ç°åœ¨éœ€è¦å›ç­”ä¸€ä¸ªå…³äºè‚ºç»“æ ¸æ‚£è€…èƒ¸è…”ç§¯æ¶²çš„é—®é¢˜ã€‚é¦–å…ˆï¼Œé¢˜ç›®ç»™å‡ºçš„æ˜¯ä¸€ä¸ª60å²ç”·æ€§ï¼Œå‡ºç°å³ä¾§èƒ¸ç–¼ï¼ŒXçº¿æ£€æŸ¥æ˜¾ç¤ºå³ä¾§è‚‹è†ˆè§’æ¶ˆå¤±ï¼Œè¯Šæ–­ä¸ºè‚ºç»“æ ¸ä¼´å³ä¾§èƒ¸è…”ç§¯æ¶²ã€‚ç°åœ¨è¦ç¡®å®šèƒ¸è…”ç§¯æ¶²çš„æ€§è´¨ï¼Œéœ€è¦ä»€ä¹ˆå®éªŒå®¤æ£€æŸ¥ã€‚\n",
      "\n",
      "é¦–å…ˆï¼Œèƒ¸è…”ç§¯æ¶²é€šå¸¸ç”±è‚ºç»“æ ¸å¼•èµ·ï¼Œå°¤å…¶æ˜¯ Secondary Lungs Abscessï¼Œä¹Ÿå°±æ˜¯è‚ºç»“æ ¸ä¼´èƒ¸è…”ç§¯æ¶²ã€‚è¿™ç§ç§¯æ¶²å¯èƒ½ç”±ç»†èŒæ„ŸæŸ“å¼•èµ·ï¼Œä¹Ÿå¯èƒ½ç”±çœŸèŒæˆ–ç—…æ¯’ï¼ˆå¦‚è‚ºç‚é“¾çƒèŒï¼‰å¼•èµ·ã€‚æ‰€ä»¥ï¼Œæˆ‘éœ€è¦è€ƒè™‘ä¸åŒç±»å‹çš„ç§¯æ¶²å¯èƒ½æœ‰å“ªäº›æŒ‡æ ‡ã€‚\n",
      "\n",
      "æ ¹æ®æˆ‘æ‰€å­¦ï¼Œèƒ¸è…”ç§¯æ¶²çš„æ€§è´¨å¯ä»¥é€šè¿‡ä»¥ä¸‹å®éªŒå®¤æ£€æŸ¥æ¥åˆ¤æ–­ï¼š\n",
      "\n",
      "1. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šè¡€é’™è¡€ç—‡é€šå¸¸åœ¨çœŸèŒæ„ŸæŸ“ï¼ˆå¦‚å¿µç èŒï¼‰æˆ–ç»†èŒæ„ŸæŸ“ï¼ˆå¦‚è‚ºç‚é“¾çƒèŒï¼‰çš„èƒ¸è…”ç§¯æ¶²ä¸­å‡ºç°ï¼Œè€Œè‚ºç»“æ ¸é€šå¸¸ä¸ä¼šå¯¼è‡´è¡€é’™è¡€ç—‡ã€‚å› æ­¤ï¼Œè¡€é’™è¡€ç—‡æ£€æŸ¥ä¸å¤ªå¯èƒ½å¸®åŠ©è¯Šæ–­ã€‚\n",
      "\n",
      "2. **è¡€å°¿æ£€æŸ¥**ï¼šè¡€å°¿å¯èƒ½å‘ç”Ÿåœ¨è‚ºç»“æ ¸æ‚£è€…ä¸­ï¼Œå°¤å…¶æ˜¯æ„ŸæŸ“ç»†èŒçš„èƒ¸è…”ç§¯æ¶²ã€‚ä½†å¦‚æœæ˜¯çœŸèŒæ„ŸæŸ“çš„èƒ¸è…”ç§¯æ¶²ï¼Œé€šå¸¸ä¸ä¼šå‡ºç°è¡€å°¿ã€‚å› æ­¤ï¼Œè¡€å°¿æ£€æŸ¥ä¹Ÿå¯èƒ½ä¸å¤ªé€‚ç”¨ã€‚\n",
      "\n",
      "3. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šå¦‚å‰æ‰€è¿°ï¼Œè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œè€Œè‚ºç»“æ ¸é€šå¸¸ä¸å¸¦æœ‰è¡€é’™è¡€ç—‡ã€‚\n",
      "\n",
      "4. **èƒ¸è…”é•œæ£€æŸ¥**ï¼šè¿™æ˜¯æ ‡å‡†çš„æ£€æŸ¥æ–¹æ³•ï¼Œç”¨äºè§‚å¯Ÿç§¯æ¶²çš„å½¢çŠ¶å’Œå¤§å°ï¼Œä½†ä¸æ˜¯è¯Šæ–­å·¥å…·ã€‚\n",
      "\n",
      "5. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šåŒæ ·ï¼Œè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "6. **ç™½ç»†èƒè®¡æ•°**ï¼šç™½ç»†èƒè®¡æ•°å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä½†è‚ºç»“æ ¸é€šå¸¸ä¸å¸¦æœ‰æ­¤ç‰¹å¾ã€‚\n",
      "\n",
      "7. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šåŒæ ·ï¼Œè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "8. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "9. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šåŒæ ·ï¼Œè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "10. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "11. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "12. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "13. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "14. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "15. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "16. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "17. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "18. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "19. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "20. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "21. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "22. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "23. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "24. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "25. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "26. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "27. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "28. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "29. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "30. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "31. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "32. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "33. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "34. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "35. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "36. **è¡€é’™è¡€ç—‡æ£€æŸ¥**ï¼šè¿™å¯èƒ½ä¸ç»†èŒæ„ŸæŸ“ç›¸å…³ï¼Œä¸é€‚ç”¨ã€‚\n",
      "\n",
      "37. **è¡€\n"
     ]
    }
   ],
   "source": [
    "# å¯¹æ¯”\n",
    "my_question = \"å¯¹äºä¸€å60å²ç”·æ€§æ‚£è€…ï¼Œå‡ºç°å³ä¾§èƒ¸ç–¼å¹¶åœ¨Xçº¿æ£€æŸ¥ä¸­æ˜¾ç¤ºå³ä¾§è‚‹è†ˆè§’æ¶ˆå¤±ï¼Œè¯Šæ–­ä¸ºè‚ºç»“æ ¸ä¼´å³ä¾§èƒ¸è…”ç§¯æ¶²ï¼Œè¯·é—®å“ªä¸€é¡¹å®éªŒå®¤æ£€æŸ¥å¯¹äº†è§£èƒ¸æ°´çš„æ€§è´¨æ›´æœ‰å¸®åŠ©ï¼Ÿ\"\n",
    "\n",
    "response = generate_response(my_question, model_sft_before, tokenizer_sft_before, inference_prompt)\n",
    "print(\"==================== æ¨¡å‹å›ç­” ====================\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-31T13:54:37.800716Z",
     "iopub.status.busy": "2025-08-31T13:54:37.800269Z",
     "iopub.status.idle": "2025-08-31T13:54:57.307366Z",
     "shell.execute_reply": "2025-08-31T13:54:57.306775Z",
     "shell.execute_reply.started": "2025-08-31T13:54:37.800695Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== æ¨¡å‹å›ç­” ====================\n",
      "<think>\n",
      "å¥½ï¼Œæˆ‘ç°åœ¨è¦å›ç­”è¿™ä¸ªåŒ»å­¦é—®é¢˜ã€‚æ‚£è€…æ˜¯28å²ç”·æ€§ï¼Œå·¥ä½œæ˜¯ç¨‹åºå‘˜ï¼Œå¸¸å¹´ç†¬å¤œï¼Œæœ€è¿‘çªç„¶æ„Ÿè§‰å¤´æ™•ç›®çœ©ï¼Œç”šè‡³æœ‰ç‚¹æ¶å¿ƒã€‚é¦–å…ˆï¼Œæˆ‘éœ€è¦åˆ†ææ‚£è€…çš„ç—‡çŠ¶å’ŒèƒŒæ™¯ã€‚\n",
      "\n",
      "æ‚£è€…é•¿æ—¶é—´ç†¬å¤œï¼Œè¯´æ˜å¯èƒ½æœ‰ç¡çœ éšœç¢ï¼Œä¹Ÿå¯èƒ½æœ‰é•¿æœŸçš„ç–²åŠ³æˆ–ç¡çœ ä¸è¶³ã€‚å¤´æ™•ç›®çœ©å’Œæ¶å¿ƒï¼Œå¯èƒ½ä¸ç¡çœ ä¸è¶³æœ‰å…³ï¼Œä¹Ÿå¯èƒ½æœ‰å…¶ä»–åŸå› ï¼Œæ¯”å¦‚å‹åŠ›ã€ç„¦è™‘ã€ç²¾ç¥ç–¾ç—…ç­‰ã€‚\n",
      "\n",
      "å¸¸è§çš„ç—‡çŠ¶åŒ…æ‹¬å¤´æ™•ç›®çœ©ã€æ¶å¿ƒå‘•åï¼Œå¯èƒ½ä¸é•¿æœŸçš„ç–²åŠ³æˆ–ç¡çœ é—®é¢˜æœ‰å…³ã€‚æ‚£è€…æœ‰é•¿æœŸç†¬å¤œçš„ä¹ æƒ¯ï¼Œå¯èƒ½å½±å“ç¡çœ ï¼Œå¯¼è‡´æŒç»­çš„å¤´æ™•ç›®çœ©å’Œæ¶å¿ƒã€‚\n",
      "\n",
      "è€ƒè™‘åˆ°è¿™äº›å› ç´ ï¼Œå¯èƒ½çš„ç–¾ç—…åŒ…æ‹¬ï¼š\n",
      "\n",
      "1. å‘¼å¸ç³»ç»Ÿç–¾ç—…ï¼šå¦‚é¼»ç‚ã€å¤šå›Šè…ºç‚ã€ä¸­è€³ç‚ã€æ”¯æ°”ç®¡ç‚ç­‰ã€‚\n",
      "2. å¿ƒè¡€ç®¡ç–¾ç—…ï¼šå¦‚é«˜è¡€å‹ã€é«˜è¡€ç³–ã€ç³–å°¿ç—…ã€å¿ƒè„‘è¡€ç®¡ç–¾ç—…ã€‚\n",
      "3. å†…è„ç–¾ç—…ï¼šå¦‚èƒƒç‚ã€èƒ°è…ºç‚ã€è‚èƒ†ç–¾ç—…ã€‚\n",
      "4. è½¯ä»¶æ•…éšœï¼šå¯èƒ½æ˜¯ç”µè„‘æ•…éšœï¼Œå¯¼è‡´å¤´æ™•ç›®çœ©ã€‚\n",
      "5. å¿ƒç†å› ç´ ï¼šé•¿æœŸçš„å‹åŠ›æˆ–ç„¦è™‘å¯èƒ½å¯¼è‡´è¿™äº›ç—‡çŠ¶ã€‚\n",
      "\n",
      "éœ€è¦è€ƒè™‘è¿™äº›å¯èƒ½æ€§ï¼Œå¯èƒ½éœ€è¦è¿›ä¸€æ­¥çš„è¯Šæ–­ï¼Œæ¯”å¦‚é€šè¿‡å½±åƒå­¦æ£€æŸ¥ï¼ˆå¦‚CTã€MRIï¼‰æ¥è¯„ä¼°æ˜¯å¦æœ‰ç¡çœ éšœç¢æˆ–å…¶ä»–æ½œåœ¨çš„ç–¾ç—…ã€‚å¦‚æœæ€€ç–‘æ˜¯ç”µè„‘æ•…éšœï¼Œå¯ä»¥å»ºè®®æ£€æŸ¥ç”µè„‘çš„ç£ç›˜æˆ–ç”µæºï¼Œçœ‹çœ‹æ˜¯å¦æ˜¯è½¯ä»¶é—®é¢˜ã€‚\n",
      "\n",
      "æ€»ç»“æ¥è¯´ï¼Œæ‚£è€…å¯èƒ½æœ‰ç¡çœ é—®é¢˜ï¼Œå¯¼è‡´æŒç»­çš„å¤´æ™•ç›®çœ©ï¼Œæˆ–è€…æœ‰é•¿æœŸçš„ç–²åŠ³æˆ–å‹åŠ›å› ç´ ï¼Œå¯èƒ½ä¸å¿ƒè„‘è¡€ç®¡ç–¾ç—…æœ‰å…³ã€‚å»ºè®®è¿›ä¸€æ­¥çš„æ£€æŸ¥æ¥æ˜ç¡®è¯Šæ–­ã€‚\n",
      "</think>\n",
      "\n",
      "å¯¹äºè¿™å28å²çš„ç”·æ€§æ‚£è€…ï¼Œå·¥ä½œæ˜¯ç¨‹åºå‘˜ï¼Œé•¿æœŸç†¬å¤œï¼Œæœ€è¿‘çªç„¶å¤´æ™•ç›®çœ©ï¼Œç”šè‡³æ¶å¿ƒï¼Œå¯èƒ½çš„ç–¾ç—…åŒ…æ‹¬ä»¥ä¸‹å‡ ç§ï¼š\n",
      "\n",
      "1. **ç¡çœ éšœç¢**ï¼šé•¿æœŸç†¬å¤œå¯èƒ½å½±å“ç¡çœ ï¼Œå¯¼è‡´æŒç»­çš„å¤´æ™•ç›®çœ©å’Œæ¶å¿ƒã€‚\n",
      "2. **ç¥ç»ç³»ç»Ÿç–¾ç—…**ï¼šå¦‚å¤šå›Šè…ºç‚ã€ä¸­è€³ç‚ã€æ”¯æ°”ç®¡ç‚ã€é¼»ç‚ç­‰ã€‚\n",
      "3. **å¿ƒè„‘è¡€ç®¡ç–¾ç—…**ï¼šå¦‚é«˜è¡€å‹ã€ç³–å°¿ç—…ã€å¿ƒè„ç—…ç­‰ã€‚\n",
      "4. **å¿ƒç†å› ç´ **ï¼šé•¿æœŸçš„å‹åŠ›æˆ–ç„¦è™‘å¯èƒ½å¼•å‘è¿™äº›ç—‡çŠ¶ã€‚\n",
      "5. **ç”µè„‘æ•…éšœ**ï¼šå¯èƒ½æ˜¯ç”µè„‘æ•…éšœå¯¼è‡´çš„å¤´æ™•ç›®çœ©ã€‚\n",
      "\n",
      "å»ºè®®è¿›ä¸€æ­¥çš„æ£€æŸ¥ï¼Œå¦‚å½±åƒå­¦æ£€æŸ¥ï¼ˆå¦‚CTã€MRIï¼‰æ¥è¯„ä¼°æ˜¯å¦æœ‰ç¡çœ é—®é¢˜æˆ–æ½œåœ¨çš„ç–¾ç—…ã€‚å¦‚æœæ€€ç–‘æ˜¯ç”µè„‘æ•…éšœï¼Œå¯ä»¥å»ºè®®æ£€æŸ¥ç”µè„‘çš„ç£ç›˜æˆ–ç”µæºï¼Œçœ‹çœ‹æ˜¯å¦æ˜¯è½¯ä»¶é—®é¢˜ã€‚\n"
     ]
    }
   ],
   "source": [
    "# å¯¹æ¯”\n",
    "my_question = \"å¯¹äºä¸€å 28 å²çš„ç”·æ€§æ‚£è€…ï¼Œå·¥ä½œæ˜¯ç¨‹åºå‘˜ï¼Œå¸¸å¹´ç†¬å¤œï¼Œæœ€è¿‘çªç„¶æ„Ÿè§‰å¤´æ™•ç›®çœ©ï¼Œç”šè‡³æœ‰ç‚¹æ¶å¿ƒã€‚è¯·é—®æœ‰å¯èƒ½æ˜¯ä»€ä¹ˆç–¾ç—…ï¼Ÿ\"\n",
    "\n",
    "response = generate_response(my_question, model_sft_before, tokenizer_sft_before, inference_prompt)\n",
    "print(\"==================== æ¨¡å‹å›ç­” ====================\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
